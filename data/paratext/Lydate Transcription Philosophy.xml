<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="tei_ms.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<TEI version="5.0" xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title type="main">How do you transcribe an item?</title>
                <editor>
                    <persName xml:id="medavis">
                        <surname>Davis</surname>
                        <forename sort="1">Matthew</forename>
                        <forename sort="2">Evan</forename>
                    </persName>
                </editor>
            </titleStmt>
            <publicationStmt>
                <publisher/>
                <pubPlace/>
                <availability status="unknown">
                    <p>No part of this publication may be reproduced, stored in a retrieval system,
                        or transmitted in any form or by any means, electronic, mechanical, or
                        otherwise, without the written permission of the publisher.</p>
                </availability>
                <date/>
            </publicationStmt>
            <sourceDesc xml:id="transcription.html">
                <bibl>Information about the transcription process and philosophy behind
                    transcription.</bibl>
            </sourceDesc>
        </fileDesc>
    </teiHeader>
    <text>
        <body>
            <p>This is actually a more complex question than it may initially seem, and is composed
                of two parts. The first part, the transcription of a witness and production of the
                resulting XML file, is more practical while the second, preparation of that
                transcription for ultimate display on the web, is far more philosophical. In either
                case, the actual work of preparing an archive of digital facsimiles such as this
                site is something akin to viewing an iceberg: the actual information you can see is
                the result of hundreds of hours of invisible labor that often goes unnoticed and
                thus is unvalued. As part of a general desire to eliminate black boxes in the
                development of scholarly work and increase transparency, I will explain the process
                as I undergo it (and with the understanding that even that invisible work relies on
                the equally invisible labor of digitizers, coders, and metadata specialists that
                often go unsung, to say nothing about the people who produced the original material
                object), but there are multiple possible ways that the same result might be
                achieved.</p>
            <head type="subhead">Practical</head>
            <p>I work primarily from two sources. Ideally, I transcribe from the actual physical
                object itself, but as most of the items in the archive are held by institutions in
                the United Kingdom this is often impractical. In those cases I will work from images
                purchased from or donated by the holding archive or taken with permission during
                archival research, and use my research time in the UK to examine the physical object
                and make notes on its composition, structure, media used, and the integrity of the
                items it contains as a physical collection of texts. The actual process of
                transcription itself occurs via entering the glyphs, as I see them, into a word
                processing document: </p>
            <p><graphic url="Images/Hm140_transcription.png"/></p>
            <p>This differs from the method generally taught, which involves writing down the
                transcription into a notebook so as to be able to capture the nuances of scribal
                hand via replication. As more and more archives are allowing researchers to take
                digital photographs of their texts for personal use, I find it easier to type out
                what I see and take reference photographs to catch oddities I might want to make
                reference to. Not to mention that this alleviates issues with misreading my own
                handwriting!</p>
            <p>Another benefit from transcribing my documents into a word processing program is that
                the two most commonly used—<ref
                    target="https://en.wikipedia.org/w/index.php?title=Docx">Microsoft Word</ref>
                and <ref target="https://en.wikipedia.org/w/index.php?title=.odt"
                    >Libre/OpenOffice</ref>—utilize (unfortunately differing) document standards
                based on wrapped XML files<note anchored="true" place="bottom" n="other">I should
                    mention here that there are specialty tools that attempt to bring word processing-like features to XML/TEI work (<ref
                        target="https://www.juxtasoftware.org/">Juxta</ref><note anchored="true"
                            place="bottom" n="other"> I should note that, as I've written about
                            <ref
                                target="https://emdr.itercommunity.org/index.php/emdr/article/view/36/2"
                                > elsewhere</ref>, Juxta comes in two varieties-a <ref
                                    target="https://www.juxtasoftware.org/download/">rather good Java
                                    program</ref> and an <ref target="http://juxtacommons.org/">online
                                        version</ref> with a reduced feature set. It appears that as of
                            September 8th, 2020 the online version is being deprecated in favor of a
                            <ref target="https://faircopyeditor.com/">new tool</ref>, and this
                            speaks to another benefit of using a basic word processor like Word or
                            OpenOffice: because they are part of standard office setups they tend to have
                            much, much longer "shelf lives" than proprietary products. While it bothers
                            me when scholars shoehorn their work into tools built for the sciences, in
                            this case I feel the benefits outweight the possible detriments.</note>, <ref
                        target="https://18thconnect.org/typewright/documents">TypeWright</ref>, <ref
                        target="https://cwrc-writer.cwrc.ca/">CWRC-Writer</ref>, and <ref
                        target="https://tapasproject.org/">TAPAS</ref> are four that immediately
                    come to mind), but in the case of all four you'll note they're either attached to
                    existing projects (and thus created for that project primarily) or have what I
                    consider a higher bar to entry than the simple Word documents that most of us
                    have used for years in our professional and academic lives. Additionally, in
                    some cases-although not in the case of the four I mention above-the tool is built
                    primarily as a means to secure funding for centers as there's more money
                    available for tool development than there is for working with the cultural
                    heritage items those tools deal with.</note>. What this means practically is
                that a Word .docx file or an OpenOffice .odt file is in fact a zipped up directory
                of multiple related files that the program parses to create the document on your
                screen. These files can be unzipped, and the underlying Extensible Markup Language
                (XML) files accessed.</p>
            <p>XML is a highly flexible and adaptable language that can be used for multiple
                purposes. What limits XML to a particular purpose is a set of metadata standards
                known as a <ref target="https://en.wikipedia.org/wiki/XML_namespace"
                >namespace</ref>. The namespace for a Microsoft Word document is called <ref
                    target="http://openxmldeveloper.org/wiki/w/wiki/introduction-to-wordprocessingml.aspx"
                    >WordprocessingML</ref> (abbreviated to w) and the namespace for the XML
                standard used in book and manuscript studies as well as literature is that of the
                    <ref target="http://www.tei-c.org/index.xml">Text Encoding Initiative</ref>, or
                TEI (abbreviated to tei). WordprocessingML's version of XML looks like this: </p>
            <code n="multiline" xml:id="xml"> 
&lt;w:p w14:paraId="75FED61C" w14:textId="77777777" w:rsidR="00F43E0B" w:rsidRDefault="00F43E0B" w:rsidP="00F43E0B"&gt;
    &lt;w:commentRangeStart w:id="0"/&gt; 
        &lt;w:r&gt; 
            &lt;w:t&gt;O&lt;/w:t&gt;
        &lt;/w:r&gt; 
    &lt;w:commentRangeEnd w:id="0"/&gt; 
    &lt;w:r&gt; 
        &lt;w:rPr&gt;
            &lt;w:rStyle w:val="CommentReference"/&gt; 
        &lt;/w:rPr&gt; 
    &lt;w:commentReference w:id="0"/&gt; 
    &lt;/w:r&gt; 
    &lt;w:r&gt; 
        &lt;w:t xml:space="preserve"&gt; 
            howe holsom and glad is the memory
        &lt;/w:t&gt; 
    &lt;/w:r&gt; 
&lt;/w:p&gt; 
&lt;w:p w14:paraId="4C68DFE4" w14:textId="21CDBFDC" w:rsidR="00F43E0B" w:rsidRDefault="00C00A8D" w:rsidP="00F43E0B"&gt; 
    &lt;w:r&gt; 
        &lt;w:t&gt;
            Of crist I
        &lt;/w:t&gt; 
    &lt;/w:r&gt; 
    &lt;w:r w:rsidR="00F43E0B"&gt; 
        &lt;w:t&gt;
            h
        &lt;/w:t&gt;
    &lt;/w:r&gt; 
    &lt;w:r w:rsidR="00F43E0B"&gt;
        &lt;w:rPr&gt; 
            &lt;w:i/&gt;
        &lt;/w:rPr&gt; 
        &lt;w:t&gt;
            es
        &lt;/w:t&gt; 
    &lt;/w:r&gt; 
    &lt;w:r w:rsidR="00F43E0B"&gt;
        &lt;w:t&gt;
            u surmountyng a
        &lt;/w:t&gt;
    &lt;/w:r&gt; 
    &lt;w:commentRangeStart w:id="1"/&gt; 
    &lt;w:r w:rsidR="00F43E0B"&gt; 
        &lt;w:t&gt;ll&lt;/w:t&gt; 
    &lt;/w:r&gt;
    &lt;w:commentRangeEnd w:id="1"/&gt; 
    &lt;w:r w:rsidR="00F43E0B"&gt; 
        &lt;w:rPr&gt;
            &lt;w:rStyle w:val="CommentReference"/&gt; 
        &lt;/w:rPr&gt; 
        &lt;w:commentReference w:id="1"/&gt; 
    &lt;/w:r&gt; 
    &lt;w:r w:rsidR="00F43E0B"&gt; 
        &lt;w:t xml:space="preserve"&gt; 
            swentes
        &lt;/w:t&gt; 
    &lt;/w:r&gt; 
&lt;/w:p&gt; </code>
            <p>Which if you've looked at any of the XML downloaded from this site or on the TEI
                Consortium's homepage you'll note is markedly different.</p>
            <p>Obviously, then, much of the markup above as well as the markup in a Word file
                applies only to the internal processes of WordprocessingML's particular version of
                XML. However, it is a fairly simple matter to transform WordprocessingML to TEI XML
                via an <ref target="xsl_word.xsl">xslt transformation</ref>. I should note here,
                however, that the transformation at that link is somewhat incomplete, as it still
                requires a manual step to paste the transformed transcription code into a prepared
                TEI document that has the necessary header information. Eventually this may be
                automated using the <code>"&lt;xi:include&gt;</code> function in an xml wrapper, by
                modifying the xslt to include the header information, or programmatically by
                including <ref
                    target="https://en.wikipedia.org/wiki/XQuery#:~:text=XQuery%20(XML%20Query)%20is%20a,%2C%20binary%2C%20etc.)."
                    >XQuery</ref> in a PHP script or Java program, but I find the manual nature of
                cutting and pasting actually adds an element of quality control that might be absent
                otherwise. </p>
            <p>Once the TEI-encoded XML (hereafter referred to as TEI) is generated from the
                WordprocessingML, I then go through the code with my original transcription and
                notes and add anything—deletions, additions, notes regarding shifts in script or
                scribe, general notes regarding oddities in the text, and other oddities I noted in
                my initial examination. Again, this portion could be done programatically by
                accessing the particular WordprocessingML file that contains the notes and referring
                back to the original document, but I use this manual step to provide a level of
                quality control, checking my transcription against the images again to ensure that
                I've been accurate and consistent in transcribing. After that is completed, the
                modified and corrected TEI is processed again to produce static HTML documents,
                which is what a viewer sees when they come to the site.</p>
            <head type="subhead">Philosophical</head>
            <p>The archive is encoded in TEI, but TEI is really just a set of agreed-upon XML
                metadata standards, enforced via a consortium, in a similar manner to the way that
                there’s a set of agreed-upon standards for the HTML markup language that is the
                underlying building blocks of the web. The setting of standards enforces a certain
                degree of interoperability that would not be possible otherwise.</p>
            <p>However, like with anything where there’s a standard, the question becomes how
                rigidly the standard should be applied and how the decisions about the standard are
                made. The <ref target="http://www.tei-c.org/About/">about page</ref> for the TEI
                Consortium states that “materials encoded with the TEI Guidelines are as various as
                its practitioners,” but at its heart, TEI is really designed around the encoding of
                content for the development of transcriptions of printed materials, quite often in
                the form of online editions.</p>
            <p>If you look at the standard structure of a TEI document, it looks something like
                this:</p>
            <code n="multiline" xml:id="xml"> 
&lt;TEI version="5.0" xmlns="http://www.tei-c.org/ns/1.0"&gt;
    &lt;teiHeader&gt; 
        &lt;fileDesc&gt; 
            &lt;titleStmt&gt; 
                &lt;title&gt;
                    The shortest TEI Document Imaginable
                &lt;/title&gt; 
            &lt;/titleStmt&gt; 
            &lt;publicationStmt&gt;
                &lt;p&gt;
                    First published as part of TEI P2, this is the P5 version using a name space.
                &lt;/p&gt; 
            &lt;/publicationStmt&gt; 
            &lt;sourceDesc&gt; 
                &lt;p&gt;
                    No source: this is an original work.
                &lt;/p&gt; 
            &lt;/sourceDesc&gt; 
        &lt;/fileDesc&gt;
    &lt;/teiHeader&gt; 
    &lt;text&gt; 
        &lt;body&gt; 
            &lt;p&gt;
                This is about the shortest TEI document imaginable.
            &lt;/p&gt; 
        &lt;/body&gt; 
    &lt;/text&gt; 
&lt;/TEI&gt; 
            </code>
            <p>In that document, there are two parts: the <code xml:id="xml">&lt;teiHeader&gt;</code>, which is
                the information about the document as a digital file (with information on the actual
                source document as a subsection)—and the <code xml:id="xml">&lt;text&gt;</code> itself. So what
                we’re seeing here is a single level of abstraction. That level of abstraction can be
                taken still further, to the point where the actual content of the item is actually
                obscured by information about that content.</p>
            <p>This descriptivist impulse is partially due to the fact that any digital item—whether
                “born digital” or transcribed—is composed of discrete pieces ultimately reduced to
                0’s and 1’s. The real, material world does not function in this way. There is a
                messiness to things that denies neat categorization. So, much as in the real world
                and with traditional editing, choices are made as to what should be foregrounded and
                what should be ignored. Buried in the TEI acronym is just one such conscious choice
                regarding what is important: the text, which is to say the written content of a
                material item or born digital artifact. The material aspects of the text-what we
                might traditionally all its paratext-are important, but are often reduced to
                descriptive material to be set aside in the header or divided off from the text
                rather than integrated alongside it. This is a function both of TEI's design and of
                the underlying abstraction-through-description XML encourages. Implicitly built into
                the name, and much of the thinking around, TEI is the attempt to delineate and
                describe what cannot really be delineated.</p>
            <p>The facts of digitization and expression of material objects as an abstraction
                presents me with a philosophical quandry. Ideas, to me, are created, transformed,
                and received not as discrete, platonic items but filtered through the tools and
                methods used both to inscribe and to interpret them. So presenting any material
                object online fully and completely as it is is an inherent impossibility. At the
                same time, however, the uniqueness of these manuscript witnesses means that they
                need to be made available much more widely than they might be otherwise.</p>
            <p>My solution to this is admittedly imperfect, and is twofold: first, I attempt
                whenever possible to remind the person viewing this site of the material existence
                of these objects. They have heft, and often are not just composed of the Lydgate
                material. A viewer in the upper left corner, giving where the particular page is
                both in the gathering and in the text as a whole, is intended to serve as a constant
                reminder of the page’s existence as part of a whole. In the case of non-codex items
                such as the Clopton Chapel, I have looked for the best method possible to provide
                the viewer with a sense of that whole, often through visualizations. Second, instead
                of the TEI encoding utilized above I use a method centered on the
                <code xml:id="xml">&lt;sourceDoc&gt;</code>, rather than <code xml:id="xml">&lt;body&gt;</code>,
                element:</p>
            <code n="multiline" xml:id = "xml"> 
&lt;sourceDoc&gt; 
    &lt;surfaceGrp n="leaf1"&gt; 
        &lt;surface facs="page1.png"&gt; 
            &lt;zone&gt;
                All the writing on page 1
            &lt;/zone&gt;
        &lt;/surface&gt; 
        &lt;surface&gt; 
            &lt;graphic url="page2-highRes.png"/&gt;
            &lt;graphic url="page2-lowRes.png"/&gt; 
            &lt;zone&gt; 
                &lt;line&gt;
                    A line of writing on page 2
                &lt;/line&gt; 
                &lt;line&gt;
                    Another line of writing on page 2
                &lt;/line&gt;
            &lt;/zone&gt; 
        &lt;/surface&gt; 
    &lt;/surfaceGrp&gt; 
&lt;/sourceDoc&gt; 
            </code>
            <p>This is a new method, included in the latest revision of the TEI standard, for
                transcriptions that are concerned with following the material object as closely as
                possible. I go a step further by placing another <code xml:id="xml">&lt;surfaceGrp&gt;</code>
                element around each gathering. In this way, the material composition of the text is
                reflected in the transcription, and the structure of the physical object can be
                inferred by just looking at the code without any specialist codicological
                training.</p>
            <p>I have failed, however, in removing abstraction and descriptivism entirely. This is
                an example from my transcription of British Library Harley 2255:</p>
            <code n="multiline" xml:id ="xml"> 
&lt;surfaceGrp xml:id="g.8" n="gathering"&gt; 
    &lt;surfaceGrp xml:id="f.66" n="folio"&gt; 
        &lt;surface n="verso"&gt; 
            &lt;label&gt;
                Folio 66 Verso
            &lt;/label&gt; 
            &lt;graphic url="British_Library_Harley_2255_f66v.jpg"/&gt;
            &lt;zone n="EETS.QD.I"&gt; 
                &lt;line n="l.1"&gt; 
                    Quis dab
                    &lt;ex&gt;
                        it
                    &lt;/ex&gt; 
                    capiti 
                &lt;/line&gt; 
                &lt;line n="l.2"&gt;
                    Meo fonte
                    &lt;ex&gt;
                        m
                    &lt;/ex&gt;
                    lac
                    &lt;ex&gt;
                        rimarium
                    &lt;/ex&gt;
                &lt;/line&gt; 
            &lt;/zone&gt; 
        &lt;/surface&gt; 
    &lt;/surfaceGrp&gt; 
&lt;/surfaceGrp&gt; 
            </code>
            <p>It should be noted, however, that the <code xml:id="xml">&lt;surfaceGrp&gt;</code>-based transcription
                methodology has one issue that tends to run at odds with my philosophy regarding transcription. 
                That is that it is designed primarily around the idea of a <emph>diplomatic</emph> transcription, 
                or a rendering of what exactly is on the page. While admirable, the issue with this in terms of 
                medieval manuscripts is that there are a number of marks on the page that are intended to represent
                abbreviations we have no modern glyphs to represent or to indicate text that can be
                expanded, again with a mark indicating that the expansion exists. As Michelle Brown
                notes, abbreviations <emph>can</emph> be mentioned by use of the apostrophe, but there's
                nothing really to indicate an expansion as a single character. The traditional way
                of getting around this is to put the expansion in rounded brackets (so like the
                parenthesis you see here), but to my mind it seems foolish to do so when there's a
                perfectly useful group of elements under the TEI standard to handle this. So what I
                have done is included <code xml:id="xml">&lt;ex&gt;</code> elements to expand any abbreviated text, with the
                idea that if someone wants to use the TEI they can either adjust the element to the
                rounded brackets or convert it to the <code xml:id="xml">&lt;text&gt;</code>-based standard fairly easily.</p>
            <p>Under the encoding I currently use, then, the structure of the codex is there and the
                majority of technical interventions, such as the <code xml:id="xml">&lt;ex&gt;</code> tags
                surrounding the expanded abbreviations, are understandable at first glance.
                Necessities regarding display on the web, however, have caused the need for several
                additional attributes—the <code xml:id="xml">@xml:id</code> and <code xml:id="xml">@n</code> in several
                places—in order for machines to render what is readily intuited from the object by a
                human properly.</p>
            <p>Note though that those interventions only exist when necessary, and that the lines
                are rendered as they appear on the page with the understanding that the reader would
                mentally expand any abbreviation, recognize gaps, and otherwise mentally do the work
                of decoding the scribe's intent that TEI tends to assume is the province of editors.
                This is an attempt to follow the second of my design principles—to defer to the
                physical object whenever possible and to avoid undue abstraction.</p>
            <p>This decision means that the text requires additional processing to be rendered for
                more quantative approaches, since the individual lines would need to be reduced
                further into individual words or segments. I am not interested in doing such work on
                this site, and so philosophically the TEI has not been rendered in order to make
                that happen. It also would be made more difficult based on the fact that Middle
                English in the fifteenth century does not have a consistent system of spelling, and
                so I have elected not to do so unless there's a pressing need. That decision,
                however, does have implications for future work with my TEI-encoded texts that would
                need to be considered should one want to take my TEI and work with it
                quantatively.</p>
        </body>
    </text>
</TEI>
